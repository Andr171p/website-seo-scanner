"""–ú–æ–¥—É–ª—å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–µ—Ä–µ–≤–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–∞–π—Ç–∞"""

from __future__ import annotations

from collections.abc import Iterator
from datetime import datetime
from urllib.parse import urlparse

from pydantic import BaseModel, Field, HttpUrl
from usp.objects.page import SitemapPage
from usp.tree import sitemap_tree_for_homepage


def parse_url_path(url: str) -> list[str]:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç URL –Ω–∞ —á–∞—Å—Ç–∏.

    –ü—Ä–∏–º–µ—Ä: "http://site.com/folder/page" -> ["folder", "page"]
    """
    path = urlparse(url).path
    return [segment for segment in path.strip("/").split("/") if segment]


class TreeNode(BaseModel):
    """–£–∑–µ–ª –¥–µ—Ä–µ–≤–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü —Å–∞–π—Ç–∞"""
    name: str
    url: HttpUrl
    priority: float | None = None
    last_modified: datetime | None = None
    children: list[TreeNode] = Field(default_factory=list)

    @property
    def is_leaf(self) -> bool:
        """–Ø–≤–ª—è–µ—Ç—Å—è –ª–∏ —É–∑–µ–ª –ª–∏—Å—Ç–æ–º"""
        return len(self.children) == 0

    def max_depth(self) -> int:
        """–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞"""
        if not self.children:
            return 0
        return max(child.max_depth() for child in self.children) + 1

    def count_nodes(self) -> int:
        """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–∑–ª–æ–≤ –≤ –¥–µ—Ä–µ–≤–µ"""
        count = 1
        for child in self.children:
            count += child.count_nodes()
        return count

    def iter_nodes(self) -> Iterator[TreeNode]:
        """–ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –≤—Å–µ–º —É–∑–ª–∞–º –¥–µ—Ä–µ–≤–∞"""
        yield self
        for child in self.children:
            yield from child.iter_nodes()

    def iter_leaves(self) -> Iterator[TreeNode]:
        """–ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –ª–∏—Å—Ç—å—è–º –¥–µ—Ä–µ–≤–∞"""
        for node in self.iter_nodes():
            if node.is_leaf:
                yield node

    def find_node(self, url: str) -> TreeNode | None:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ –µ—ë URL"""
        if self.url == url:
            return self
        for child in self.children:
            found = child.find_node(url)
            if found:
                return found
        return None

    def to_string(self, max_depth: int | None = None) -> str:
        """–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–µ—Ä–µ–≤–∞ –≤ —á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
        lines: list[str] = []
        self.draw_tree_lines(lines, max_depth=max_depth)
        return "\n".join(lines)

    def draw_tree_lines(
            self,
            lines: list[str],
            max_depth: int | None = None,
            current_depth: int = 0,
            prefix: str = "",
            is_last: bool = True,
    ) -> None:
        """–§–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–µ—Ä–µ–≤–∞"""
        if max_depth is not None and current_depth >= max_depth:
            return
        meta_parts: list[str] = []
        if self.priority is not None:
            meta_parts.append(f"–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {self.priority}")
        if self.last_modified:
            meta_parts.append(f"–ü–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ: {self.last_modified.strftime("%d.%m.%Y")}")
        meta_str = " [" + ", ".join(meta_parts) + "]" if meta_parts else ""
        if current_depth == 0:
            icon = "üåê"
            line = f"{icon} {self.name} ({self.url}){meta_str}"
            lines.append(line)
        else:
            icon = "üìÑ" if self.is_leaf else "üìÅ"
            connector = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
            line = f"{prefix}{connector}{icon} {self.name}{meta_str}"
            lines.append(line)
        new_prefix = prefix if current_depth == 0 else prefix + ("    " if is_last else "‚îÇ   ")
        for i, child in enumerate(self.children):
            is_last_child = (i == len(self.children) - 1)
            child.draw_tree_lines(
                lines, max_depth, current_depth + 1, new_prefix, is_last_child
            )

    def last_site_change(self) -> datetime | None:
        """–ü–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –Ω–∞ —Å–∞–π—Ç–µ"""
        latest = self.last_modified
        for node in self.iter_nodes():
            if node.last_modified and (latest is None or node.last_modified > latest):
                latest = node.last_modified
        return latest

    def last_changed_node(self) -> TreeNode:
        """–ü–æ—Å–ª–µ–¥–Ω—è—è –∏–∑–º–µ–Ω—ë–Ω–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
        latest_node = self
        for node in self.iter_nodes():
            if node.last_modified and \
                    (latest_node is None or node.last_modified > latest_node.last_modified):
                latest_node = node
        return latest_node


def add_page_to_tree(
        base_url: str,
        root: TreeNode,
        page: SitemapPage,
        segments: list[str],
        current_depth: int = 0
) -> None:
    if current_depth >= len(segments):
        return
    current_segment = segments[current_depth]
    node: TreeNode | None = next(
        (child for child in root.children if child.name == current_segment), None
    )
    if node is None:
        path_part = "/".join(segments[:current_depth + 1])
        full_url = f"{base_url.rstrip("/")}/{path_part}"
        node = TreeNode.model_validate({
            "name": current_segment,
            "url": full_url,
            "priority": page.priority,
            "last_modified": page.last_modified,
        })
        root.children.append(node)
    add_page_to_tree(base_url, node, page, segments, current_depth + 1)


def build_site_tree(url: str) -> TreeNode:
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å—Ç—Ä–æ–∏—Ç –¥–µ—Ä–µ–≤–æ —Å–∞–π—Ç–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º –∏–∑ sitemap.xml.

    :param url: URL –∞–¥—Ä–µ—Å —Å–∞–π—Ç–∞.
    :return –ü–æ—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –¥–µ—Ä–µ–≤–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å–∞–π—Ç–∞.
    """
    name = (
        url
        .replace("http://", "")
        .replace("https://", "")
        .replace("/", "")
    )
    root = TreeNode(name=name, url=HttpUrl(url))
    sitemap = sitemap_tree_for_homepage(url, use_robots=False)
    for page in sitemap.all_pages():
        segments = parse_url_path(page.url)
        add_page_to_tree(url, root, page, segments)
    return root
